version: '3.8'

services:

  vllm:
    image: quay.io/modh/vllm:rhoai-2.19-cpu
    container_name: vllm
    ports:
      - "30000:8000"
    command: >
      --model BAAI/bge-reranker-large
      --port 8000
      --host 0.0.0.0
      --max-model-len 1024
    environment:
      - VLLM_USE_MODE=cpu
      - OMP_NUM_THREADS=8
    volumes:
      - /root/.cache/huggingface:/root/.cache/huggingface
    restart: unless-stopped

  ollama:
    image: quay.io/anchinna/ollama:v1
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - /root/henrik/mymodels:/models
    restart: unless-stopped
    tty: true
    stdin_open: true

volumes:
  ollama_data:
